{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Py07_3selenium.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVqzdvIY5sNW"
      },
      "source": [
        "# Crawler using selenium\n",
        "\n",
        "https://stackoverflow.com/questions/51046454/how-can-we-use-selenium-webdriver-in-colab-research-google-com\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6sfnrFQ2Ty4"
      },
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NrU9OXfGj5W"
      },
      "source": [
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwHMgqC_5fSn"
      },
      "source": [
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "#wd.get(\"https://www.webite-url.com\")\n",
        "wd.get(\"https://www.asia.edu.tw/EN/news1.php?y=2021\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRFVr0DOG0ak"
      },
      "source": [
        "elem = wd.find_element_by_tag_name(\"a\")\n",
        "print(elem.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoQ5scYO_5Ta"
      },
      "source": [
        "elements = wd.find_elements_by_tag_name(\"a\")\n",
        "for element in elements:\n",
        "    print(element.get_attribute('href'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyI5KSM1_L2e"
      },
      "source": [
        "import re\n",
        "pattern = re.compile('.*news1_detail.php\\?.*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rImzJxT1-ja6"
      },
      "source": [
        "elements = wd.find_elements_by_tag_name(\"a\")\n",
        "for element in elements:\n",
        "    matched = re.match(pattern,element.get_attribute('href'))\n",
        "    #print(matched)\n",
        "    if matched is not None:\n",
        "      try:\n",
        "        caption=element.find_element_by_tag_name('b')\n",
        "        print(caption.text)\n",
        "      except:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEXIs6nQ5q2l"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy0G6a9R1CUX"
      },
      "source": [
        "#Collect school news\n",
        "#https://www.asia.edu.tw/EN/news1.php?y=2020\n",
        "\n",
        "from urllib import request\n",
        "with request.urlopen('https://www.asia.edu.tw/EN/news1.php?y=2021') as response:\n",
        "    html = response.read().decode('utf-8')\n",
        "    print(html)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuOk-Jcw1Qe5"
      },
      "source": [
        "#print(html)\n",
        "import re\n",
        "count = 0\n",
        "pattern = '<font color=\"#446666\" face=\"Arial\" size=\"2\">\\['\n",
        "pattern2 = '<font color=\"#446666\" face=\"Arial\" size=\"2\"><b>'\n",
        "for pos in re.finditer(pattern, html):\n",
        "    pos2 = html.find('] </font>', pos.end())\n",
        "    datestr = html[pos.end()+1:pos2]\n",
        "    pos3 = html.find(pattern2, pos2+4)+len(pattern2)\n",
        "    pos4 = html.find('</b>', pos3)\n",
        "    titlestr = html[pos3:pos4]\n",
        "    print(f\"Date: {datestr}->Title: {titlestr}\")\n",
        "    count = count + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ3pLTGItElB"
      },
      "source": [
        "import re\n",
        "from urllib import request\n",
        "count = 0\n",
        "sss = [\"2009\",\"2010\", \"2011\", \"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\"2018\",\"2019\",\"2020\",\"2021\"]\n",
        "pattern = '<font color=\"#446666\" face=\"Arial\" size=\"2\">\\['\n",
        "pattern2 = '<font color=\"#446666\" face=\"Arial\" size=\"2\"><b>'\n",
        "for year in sss:\n",
        "    with request.urlopen('http://www.asia.edu.tw/EN/news1.php?y='+year) as response:\n",
        "        html = response.read().decode('utf-8')\n",
        "        #print(html)\n",
        "        for pos in re.finditer(pattern, html):\n",
        "          pos2 = html.find('] </font>', pos.end())\n",
        "          datestr = html[pos.end():pos2]\n",
        "          pos3 = html.find(pattern2, pos2+4)+len(pattern2)\n",
        "          pos4 = html.find('</b>', pos3)\n",
        "          titlestr = html[pos3:pos4]\n",
        "          print(f\"Date: {datestr}->Title: {titlestr}\")\n",
        "          count = count + 1\n",
        "print (count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyyzYF7H3mWv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTwpxXFW5_tc"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}